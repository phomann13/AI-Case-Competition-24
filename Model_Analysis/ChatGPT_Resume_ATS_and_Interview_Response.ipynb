{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y portaudio19-dev libportaudio2\n",
        "!pip install openai sounddevice scipy PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA6sFL9Co1nl",
        "outputId": "65a62dde-fba2-4816-ea94-bc0420b92f22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libportaudiocpp0\n",
            "Suggested packages:\n",
            "  portaudio19-doc\n",
            "The following NEW packages will be installed:\n",
            "  libportaudio2 libportaudiocpp0 portaudio19-dev\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 188 kB of archives.\n",
            "After this operation, 927 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudio2 amd64 19.6.0-1.1 [65.3 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudiocpp0 amd64 19.6.0-1.1 [16.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 portaudio19-dev amd64 19.6.0-1.1 [106 kB]\n",
            "Fetched 188 kB in 1s (333 kB/s)\n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 123623 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package libportaudiocpp0:amd64.\n",
            "Preparing to unpack .../libportaudiocpp0_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package portaudio19-dev:amd64.\n",
            "Preparing to unpack .../portaudio19-dev_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Setting up libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Setting up portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.2)\n",
            "Requirement already satisfied: sounddevice in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice) (1.17.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice) (2.22)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkSQxSXqnl5Q",
        "outputId": "a1dc8927-365f-40af-f5f3-f7cdc5a4e107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resume Score and Feedback:\n",
            "90/100\n",
            "\n",
            "Explanation:\n",
            "\n",
            "This candidate is in the strong batch for this role and there are several reasons for this assessment: \n",
            "\n",
            "1. Work Experience: The candidate has worked as an Associate Data Scientist/Statistician, where he conducted statistical analysis on large data sets using languages (Python, SQL) required by the job description.\n",
            "\n",
            "2. Hands-on Projects: The candidate has worked on various real-world projects involving neural networks, ETL pipelines, and data visualization which directly mirrors the responsibilities outlined in the job description.\n",
            "\n",
            "3. Technical Skills: The candidate is proficient in Python, SQL, and R along with ML Packages, skills which are expressly required in the job description. Moreover, he possesses experience with Tableau-like software for data visualizations (matplotlib, ggplot2) and ETL pipeline, which is a need for this role too.\n",
            "\n",
            "4. Education: While the candidate's Bachelor's degree is in Computational Data Science (which neatly aligns), his Master's degree in Information Systems also imparts data science knowledge.\n",
            "\n",
            "Recommendations for improvement:\n",
            "\n",
            "1. While the resume demonstrates ample evidence of problem-solving abilities, it would be beneficial for the candidate to highlight more direct client interactions or stakeholder engagements, as communication and understanding clientâ€™s challenges is important in the role.\n",
            "\n",
            "2. The job description notes that the role requires domestic travel up to 5% of the time. Any evidence of the candidate's ability or willingness to travel would enhance their qualification for the role.\n",
            "\n",
            "3. The candidate could benefit from listing direct experience with delivering insights that drive business solutions or optimize customer experiences, as these are key aspects of the role.\n",
            "\n",
            "4. Although the candidate's shift from full stack development to data science indicates versatility, his brief stint as a full stack developer may not be as relevant to the role. \n",
            "\n",
            "Overall, the candidate is a solid fit but could improve by demonstrating more relevant experience in some areas indicated in the job description.\n",
            "\n",
            "Interview Responses Evaluation:\n",
            "\n",
            "Question: 'Tell me about yourself.'\n",
            "Transcribed Response: Hello my name is Wesley Huang. I completed my undergraduate degree in data science and I'm now completing my master's degree in information systems. I have a year experience working as a data scientist at Periton, working on social security fraud and also machine learning research. Within those research I used SQL, Python to complete data analysis and thank you.\n",
            "Score and Feedback for the response to 'Tell me about yourself.':\n",
            "85/100\n",
            "\n",
            "Feedback:\n",
            "Wesley, your introduction is relevant and clear. You provided your education and work background, which is great. It's also good that you've given details about your previous work, showing that you can apply your skills to practical situations. However, you could improve by giving more specific details about the projects you worked on or the impact of your work at Periton. Also, a bit more personal touch, such as your ambition or motivation, would make the response richer and more engaging. Lastly, \"and thank you\" sounds abrupt; you could close with something like \"I'm looking forward to bringing these skills to your company\".\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import PyPDF2\n",
        "import sounddevice as sd\n",
        "from scipy.io.wavfile import write\n",
        "import tempfile\n",
        "\n",
        "# Initialize OpenAI API key\n",
        "openai.api_key = \"api-key\"\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extract text from a PDF file.\"\"\"\n",
        "    with open(pdf_path, \"rb\") as file:\n",
        "        # Use PdfReader instead of the deprecated PdfFileReader\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page_num in range(len(pdf_reader.pages)): # Use len(pdf_reader.pages) to get page count\n",
        "            text += pdf_reader.pages[page_num].extract_text() # Access pages using pages attribute\n",
        "    return text\n",
        "\n",
        "def get_resume_score(resume_text, job_description):\n",
        "    \"\"\"Get a score for the resume against a job description.\"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    You are a recruitment AI. Evaluate this resume based on the job description provided.\n",
        "    Return a score out of 100, with a detailed explanation if possible.\n",
        "\n",
        "    Job Description:\n",
        "    {job_description}\n",
        "\n",
        "    Resume:\n",
        "    {resume_text}\n",
        "\n",
        "    Score (Formatted as x/100):\n",
        "    \"\"\"\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "\n",
        "    # Extract the score from the response\n",
        "    score_output = response.choices[0].message.content\n",
        "    return score_output\n",
        "\n",
        "def transcribe_audio(audio_file_path):\n",
        "    \"\"\"Use OpenAI's Whisper ASR to transcribe audio.\"\"\"\n",
        "    with open(audio_file_path, \"rb\") as audio_file:\n",
        "        transcript = openai.audio.transcriptions.create(\n",
        "            file=audio_file,\n",
        "            model=\"whisper-1\"\n",
        "        )\n",
        "    return transcript.text\n",
        "\n",
        "def evaluate_interview_response(question, transcribed_response):\n",
        "    \"\"\"Evaluate a user's interview response based on a sample question and return a score out of 100.\"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    You are an interview coach. Rate the user's response to the interview question out of 100,\n",
        "    considering relevance, clarity, and alignment with the job description. Provide feedback as well.\n",
        "\n",
        "    Interview Question:\n",
        "    {question}\n",
        "\n",
        "    User's Response:\n",
        "    {transcribed_response}\n",
        "\n",
        "    Score and Feedback (Formatted as x/100):\n",
        "    \"\"\"\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "\n",
        "    # Extract the score and feedback from the response\n",
        "    score_output = response.choices[0].message.content\n",
        "    return score_output\n",
        "\n",
        "# Main function to load PDF, get resume score, and evaluate interview responses\n",
        "def main(pdf_path, job_description, interview_questions, audio_file_paths):\n",
        "    resume_text = extract_text_from_pdf(pdf_path)\n",
        "    resume_score = get_resume_score(resume_text, job_description)\n",
        "    print(\"Resume Score and Feedback:\")\n",
        "    print(resume_score)\n",
        "\n",
        "    print(\"\\nInterview Responses Evaluation:\")\n",
        "    for question, audio_file in zip(interview_questions, audio_file_paths):\n",
        "        print(f\"\\nQuestion: '{question}'\")\n",
        "\n",
        "        transcribed_response = transcribe_audio(audio_file)  # Transcribe the corresponding audio file\n",
        "        print(f\"Transcribed Response: {transcribed_response}\")\n",
        "\n",
        "        response_score = evaluate_interview_response(question, transcribed_response)\n",
        "        print(f\"Score and Feedback for the response to '{question}':\")\n",
        "        print(response_score)\n",
        "\n",
        "# Usage\n",
        "job_description = \"\"\"\n",
        "Job Description\n",
        "\n",
        "Visa U.S.A. Inc., a Visa Inc. company, needs a Data Scientist (multiple openings) in Washington DC to\n",
        "\n",
        "Brainstorm innovative ways to use unique data to answer business problems.\n",
        "Communicate with clients to understand the challenges they face and convince them with data.\n",
        "Extract and understand data to form an opinion on how to best help clients and derive relevant insights.\n",
        "Develop visualizations to make complex analyses accessible to a broad audience.\n",
        "Find opportunities to craft products out of analyses that are suitable for multiple clients.\n",
        "Work with stakeholders throughout the organization to identify opportunities for leveraging Visa data to drive business solutions.\n",
        "Mine and analyze data from company databases to drive optimization and improvement of product, marketing techniques and business strategies for Visa and its clients.\n",
        "Assess the effectiveness and accuracy of new data sources and data gathering techniques.\n",
        "Develop custom data models and algorithms to apply to data sets.\n",
        "Use predictive modeling to increase and optimize customer experiences, revenue generation, data insights, advertising targeting and other business outcomes.\n",
        "Develop processes and tools to monitor and analyze model performance and data accuracy.\n",
        "Domestic travel may be required up to 5% of the time.\n",
        "Position reports to the Washington, DC office and may allow for partial telecommuting.\n",
        "\n",
        "Qualifications\n",
        "\n",
        "Basic Qualifications:\n",
        "\n",
        "Employer will accept a Bachelor's degree in Statistics, Operations Research, Economics, Computer Science or related field and 2 years of experience in the job offered or in a data scientist-related occupation.\n",
        "Position requires experience in the following:\n",
        "Extracting and aggregating data from large data sets using SQL or other similar tool;\n",
        "Developing visualizations in Tableau or other similar software, and communicating insights from complex analyses to a broader audience;\n",
        "Understanding and analyzing data using statistical software, such as Python, SAS, R, or Stata;\n",
        "Data mining and statistical modeling (e.g., regression modeling, clustering techniques, or decision trees, etc.); and\n",
        "Developing custom data models and algorithms to apply to data sets.\n",
        "\"\"\"\n",
        "pdf_path = \"/content/Weslee_Hwang_Resume.pdf\"\n",
        "interview_questions = [\n",
        "    \"Tell me about yourself.\",\n",
        "\n",
        "]\n",
        "\n",
        "audio_file_paths = [\n",
        "    \"/content/interview_question1.m4a\",  # Audio file for question 1\n",
        "\n",
        "]\n",
        "\"\"\"\n",
        "\"Why are you interested in this role?\",\n",
        "    \"Describe a challenging project you've worked on and how you managed it.\"\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "\"path/to/your_audio_file_2.wav\",  # Audio file for question 2\n",
        "\"path/to/your_audio_file_3.wav\",  # Audio file for question 3\n",
        "\"\"\"\n",
        "\n",
        "main(pdf_path, job_description, interview_questions, audio_file_paths)"
      ]
    }
  ]
}